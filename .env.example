# Ollama (local or remote)
OLLAMA_HOST=http://localhost:11434
# OLLAMA_PORT=11434
# Set if your remote Ollama endpoint requires bearer auth.
OLLAMA_API_KEY=

# Model selection
# Backward-compatible general model override (used if specific vars are absent)
LLM_MODEL=qwen2.5:32b-instruct
# Main Wikidata RAG agent model
WIKIDATA_RAG_MODEL=qwen2.5:32b-instruct
# Prompt-only baseline model
PROMPT_ONLY_MODEL=qwen2.5:32b-instruct
# RAGTruth evaluator model (Ollama)
RAGTRUTH_MODEL=qwen2.5:32b-instruct
# OpenAI judge model
OPENAI_JUDGE_MODEL=gpt-4o
# Evaluation model device selection: auto | cuda | cpu | mps
VECTARA_DEVICE=auto
AIMON_DEVICE=auto

# OpenAI (required only for --llm-judge)
OPENAI_API_KEY=

# Hugging Face (optional, improves Hub download rate limits)
HF_TOKEN=

# LangSmith (optional tracing/observability)
LANGSMITH_TRACING=false
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=
